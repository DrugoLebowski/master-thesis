In this chapter we initially introduce shortly the used frameworks DENN (Differential Evolution Neural Network) and Theano, passing then to speak about the implementations.

\section{DENN}\label{sec:DENN}
DENN is a framework written in C++ by Gabriele Di Bari and Mirco Tracolli, based on their thesis work. It aims to apply the Differential Evolution concepts on the ANN training as an alternative to Gradient-based algorithms. 

It is initially created as a TensorFlow extension due to the performance and simplicity offered by this latter, but now is completely based on the C++ library Eigen due to its implementation based on the high performance library LAPACK written in Fortran 77.

\subsection{How does it work}
DENN is a framework that aims to help the developer to construct a system for train Neural Networks with Differential Evolution. To achieve this goal, DENN is structured in pluggable modules through which is decided how the neural network should be trained. For example, let the Differential Evolution configuration JADE/Rand/1/Bin - JADE, Rand/1 and Bin are three modules that can be selected for the training process at the time of configuration of DENN. The plug-in that could be used are not only for the DE things, but also regard the dataset\footnote{Where is it, how to manage it, etc.}, how the neural network should be structured\footnote{How many levels and the activation functions} and, more important, what kind of neural network you want instruct\footnote{At this time, DENN can trains only feed-forward networks.}. Some of the configuration parameters can be found in the Table \ref{tbl:denn-parameters}.\newline\newline
However, what really changes in DENN respect to the standard Differential Evolution is how the population evolves. As stated in the Chapter \ref{chap:differential-evolution}, Differential Evolution bases its functioning also on the existence of a population of vectors, called \textit{NP}, that is paralleled evolved by the optimization algorithm aiming to arrive to the fitness function minimum value, i.e. to a solution vector which has the fitness minimum value. By the definition of DE, it is assumed that vectors are bi-dimensional, i.e. a list of features to optimize. Hence in DENN, since the population is composed by neural networks it cannot be used as is, instead the individuals must be managed as a set of weights and biases matrices, i.e. every individual is a neural network and is formed by a weights and biases matrices set. Hence, the mutation and crossover actions are not executed over the whole structure of individuals, but singularly over their subcomponents.\newline\newline
For a better explanation, let's examine the mutation phase through an example. Let the Neural Networks population \textit{NP}, the mutation strategy Rand/1, $r_1, r_2$ and $r_3$ three mutually exclusive indexes, the donor $\textbf{u}_{1}$ is created as follows:
\begin{align}
	\textbf{u}_{1}^{w_1} &= \textbf{x}_{r_1}^{w_1} + F \cdot (\textbf{x}_{r_2}^{w_1} - \textbf{x}_{r_3}^{w_1}) \\
	\textbf{u}_{1}^{b_1} &= \textbf{x}_{r_1}^{b_1} + F \cdot (\textbf{x}_{r_2}^{b_1} - \textbf{x}_{r_3}^{b_1}) \\
	\cdots \cr
	\textbf{u}_{1}^{w_{|\textbf{HL}|}} &= \textbf{x}_{r_1}^{w_{|\textbf{HL}|}} + F \cdot (\textbf{x}_{r_2}^{w_{|\textbf{HL}|}} - \textbf{x}_{r_3}^{w_{|\textbf{HL}|}}) \\
	\textbf{u}_{1}^{b_{|\textbf{HL}|}} &= \textbf{x}_{r_1}^{b_{|\textbf{HL}|}} + F \cdot (\textbf{x}_{r_2}^{b_{|\textbf{HL}|}} - \textbf{x}_{r_3}^{b_{|\textbf{HL}|}})
\end{align}
where $w_i$ and $b_i$ represent the weights and bias vectors of the $\textrm{i}^{\textrm{th}}$ level and \textbf{HL} is the hidden layers set. The same work is made also for the crossover phase, so we do not explain it with an example which is leaved to the reader.

\begin{table}[]
\centering
\label{my-label}
\begin{tabular}{|l|l|}
\hline
Argument     & Description \\ \hline \hline

\multicolumn{2}{|c|}{\textbf{Execution args}} \\ \hline
threads\_pop & Executed threads of DENN \\ \hline
seed     	 & Distribution seed \\ \hline
instance		 & Type of model (nram/default) \\ \hline \hline

\multicolumn{2}{|c|}{\textbf{Batch info}} \\ \hline
batch\_size  	 & Number of training examples \\ \hline
batch\_offset	 & Examples per batch \\ \hline
use\_validation & Activate pop validation at the end of a sub-geneneration \\ \hline
cumpter\_test\_per\_pass     	 & Compute the test accuracy for each pass \\ \hline \hline

\multicolumn{2}{|c|}{\textbf{DE}} \\ \hline
generations  	 & Total number of generations \\ \hline
sub\_gens  	 	& Number of sub-generations \\ \hline
number\_parents  	 	& DE population size \\ \hline
f						& DE F coefficient \\ \hline
cr						& DE CR coefficient \\ \hline
evolution\_method 		& Evolution method (JADE/SHADE/L-SHADE) \\ \hline
mutation 				& Mutation method (degl/curr\_p\_best) \\ \hline
crossover				& Crossover method (bin/exp/interm) \\ \hline

\multicolumn{2}{|c|}{\textbf{Network}} \\ \hline
hidden\_layers  	 		& Levels size \\ \hline
activation\_functions  	& Activation functions of levels \\ \hline

\multicolumn{2}{|c|}{\textbf{NRAM}} \\ \hline
task  	 		& Task to execute \\ \hline
max\_int  		& Max int in the set \\ \hline
n\_registers  	& Registers to use \\ \hline
time\_steps  	& Execution timesteps \\ \hline
gates  			& Gates to use \\ \hline
step\_gen\_change\_difficulty & Number of gen where the same difficulty is used  \\ \hline

\end{tabular}
\caption{Some arguments used in a DENN's configuration file.}
\label{tbl:denn-parameters}
\end{table}

\section{Theano}
Theano is a Python library created at LISA labs of University of Montreal, which lets to define easily complex mathematical expressions and execute them efficiently in the CPU and GPU specially with those which involves multi-dimensional arrays. The expressions definition is made through the creation of computational graph which is then executed and, if requested, automatic differentiated with an automatic differentiator, e.g. when one would calculate the gradient. However, how we see later, the performance on CPU is quite slower respect to DENN. %TODO

\section{Implementation}
Our thesis work are sub-divided in two parallel projects: a refactoring of the already existing project\footnote{\hyperref[https://github.com/gibiansky/experiments/tree/master/nram]{https://github.com/gibiansky/experiments/tree/master/nram}} of Andrew Gibiansky, written in Python and based on Theano, to which some parts of NRAM and a parametrization system are missing and an implementation from zero of NRAM based on what is offered by DENN.

\subsection{Preface}
Because some problems are too complex to be learn by NRAM, we have also used some of the technique that have been used in the original paper \cite{NRAM:2016}.

\paragraph{Gradient clipping}
The size of the model can be extremely huge and moreover extremely depth, due to the execution in various timesteps. In this types of networks the gradient can often explodes, as noticed in \cite{Bengio1994LearningLD}. Hence, to resolve this problem, in Theano implementation all the gradients are clipped in the range $[-C_1, C_1]$ and successively rescaled, such that its $L_2$\footnote{Let $\textbf{x} = [x_1, x_2, \dots, x_n]$, the norm $L_2$ is defined as $|\textbf{x}| = \sqrt{\sum\limits_{k=1}^{n}|x_i|^2}$.} norm is not bigger than some constant $C_2$.

\paragraph{Noise}
As noticed in \cite{Neelakantan2015AddingGN}, in Theano implementation after that the gradients are computed, clipped and rescaled is added Gaussian noise, whose variance decays over time.

\paragraph{Entropy}
As for \cite{NRAM:2016}, we also noticed that the network can fix the pointer in some value. Although it could be an advantage in some cases, however, if this happens too early in the training, it could forces the network to stay fixed on some pointer with a very small chances of change. Hence, to alleviate this condition, we give to the network a sort of a ``entropy bonus'' which decreases over time. This entropy is computed for each generated distribution\footnote{We have identified these distributions be those in the memory.} by the neural network with the Shannon entropy and is multiplied for the following coefficient that decreases over time
\begin{equation}
	E = e * d^{t}
\end{equation}
where $e$ is the entropy coefficient, $d$ is the entropy coefficient's decay and $t$ is the timestep. After that, the computed value is subtracted from timestep cost.

\paragraph{Curriculum training}
As noticed by \cite{Bengio2009CurriculumL} and \cite{Zaremba2014LearningTE}, curriculum learning is crucial for train very deep neural networks. Hence, as in the original paper we used the curriculum learning from \cite{Zaremba2014LearningTE} with small modifications.

For each task we have defined manually a set of increasing difficulties, where a difficulty $d$ is defined as a tuple containing the length of working sequence and the number of timesteps of running. During the training a difficulty is selected according to the current difficulty $D$ as follows:
\begin{itemize}
	\item{with probability 10\%: pick $d$ randomly from the set of all difficulties according to a uniform distribution.}
	\item{with probability 25\%: pick $d$ randomly from the set $[1, D + e]$ according to a uniform distribution, with $e$ generated from a geometric distribution with a success probability of 0.5.}
	\item{with probability 65\%: set $d = D + e$ where $e$ is sampled as above.}
\end{itemize}
How frequently the difficulty is changed is decided by the user from command line when DENN is launched, indicating the number of generations in which the difficulty (thus also the dataset) is hold for the training.

\subsection{How we did it}
The implementation of NRAM is similar between the two solutions. What is different between them is how the optimal neural network is searched. As stated previously, in DENN is searched through a parallel evolution of a population of neural networks, differently to Theano implementation where the neural network is trained applying the ADAM algorithm. Hence, leaving out this framework specific algorithm we speak only about the NRAM implementation which is presented for simplicity as pseudocode\footnote{The entire code is available at \href{https://github.com/Gabriele91/DENN-LITE/tree/nram}{https://github.com/Gabriele91/DENN-LITE/tree/nram}}.\newline\newline
The principal block of NRAM can be seen in Algorithm \ref{alg:nram-main-block}. The execution starts with the setting of some variables, such as cost variable and the constants used for entropy computing. The main cycle is at Line \ref{lst:nram-timesteps} - in every timestep the network releases all the coefficients, i.e. the circuit connections, at Line \ref{lst:nram-nn-predict}. At Line \ref{lst:nram-run-circuit} is executed the circuit, with the Algorithm \ref{alg:nram-run-circuit} - it returns the willingness of terminate the execution with which is computed from Line \ref{lst:nram-cost-1} to \ref{lst:nram-cost-2} the timestep cost, added later to the total cost. The ``magic'' of NRAM happens in Algorithm \ref{alg:nram-run-circuit}, where the circuit is run. From Line \ref{lst:nram-exec-circuit-1} to \ref{lst:nram-exec-circuit-2}, each gate in the list \textbf{Gates} is executed, getting an input\footnote{Depending by the type - Costant gate produce a constant output without getting an input, unary and binary gate gate get, respectively, one and two input.} and producing an output, which might be accessed later by another gate. From Line \ref{lst:nram-up-reg-1} to \ref{lst:nram-up-reg-2}, the registers are updated.
\newline\newline
As it can be seen in the Lines \ref{lst:nram-avg-1}, \ref{lst:nram-avg-2}, \ref{lst:nram-avg-3} and \ref{lst:nram-avg-4}, the selection of gates's input and registers's new content is made through the function in Algorithm \ref{alg:nram-average} which do a weighted average. An example of gate is visible in Algorithm \ref{alg:nram-gate-add} - the \textbf{add} gate compute the summation of two number represented as two probability distributions. Finally, the functions \textsc{GetGateCoefficient} and \textsc{GetRegisterCoefficient} are purely conceptual functions which indicates a method with which the coefficients are get.

\begin{algorithm}
	\begin{algorithmic}[1]
		\Function{Add}{A, B, IMem, MaxInt}
			\State{C = \Call{Zero(MaxInt)}{}}\Comment{Matrix of zeros where is stored the Add's output} 
			\For{$i \in [0, \textrm{MaxInt} - 1]$}
				\For{$j \in [0, \textrm{MaxInt} - 1]$}
					\State{C[j] += A[i] * B[(j - i) \% MaxInt]}
				\EndFor{}
			\EndFor{}
			\State{\Return{C}}
		\EndFunction
	\end{algorithmic}
	\caption{Example of NRAM gate.}
	\label{alg:nram-gate-add}
\end{algorithm}

\begin{algorithm}
	\begin{algorithmic}[1]
		\Function{NRAM}{NeuralNetwork, BatchSize, IMem, OMem, CostMask, MaxInt, T, Gates}
			\State{Cost = 0.0}			
            	\State{ProbIncomplete = 1.0}
            	\State{CumProbComplete = 0.0};
            	\State{$p_T = 1.0$}
            	\State{EntropyCoeff = 0.1}
            	\State{EntropyDecay = 0.999}
			\For{$t\in[1, \dots, T]$}\label{lst:nram-timesteps}
				\State{Conf = \Call{NeuralNetwork.predict()}{}}\label{lst:nram-nn-predict}
				\State{$f_i$ = \Call{RunCircuit}{Gates, Conf, Regs, IMem, MaxInt}}\label{lst:nram-run-circuit}
				\State{}
				\If{t == T}\label{lst:nram-cost-1}
					\State{$p_T$ = 1 - CumProbComplete}
				\Else
					\State{$p_T$ = $f_i$ * ProbIncomplete}
				\EndIf
				\State{}
               	\State{CumProbComplete = CumProbComplete + $p_t$}
                	\State{ProbIncomplete = ProbIncomplete * ($1 - f_i$)}
				\State{}
                	\State{EntropyWeight = $\textrm{EntropyCoeff}*\textrm{EntropyDecay}^t$}
                	\State{EntropyCost = EntropyCost+\Call{Entropy}{IMem} * EntropyWeight}
				\State{}
                	\State{Cost += \Call{CalculateCost}{InMem, OutMem, CostMask} - EntropyCost}\label{lst:nram-cost-2}
			\EndFor{}
			\State{}
			\State{\Return Cost}
		\EndFunction
	\end{algorithmic}
	\caption{Main block's pseudocode of NRAM.}\label{alg:nram-main-block}
\end{algorithm}

\begin{algorithm}
	\begin{algorithmic}[1]
		\Function{RunCircuit}{Gates, Conf, Regs, IMem, MaxInt}
			\State{RegsAndOutput = \Call{Copy}{Regs}}
			\State{}
			\ForEach{$g\in \textrm{Gates}$}\Comment{Run of the circuit}\label{lst:nram-exec-circuit-1}
				\If{\Call{g.isConstant}}
					\State{GateResult = g.\Call{Value}{}}
				\ElsIf{\Call{g.isUnary}}
					\State{Coeff = \Call{GetGateCoefficient}{Conf, g}}
					\State{InputValue = \Call{Avg}{RegsAndOutput, Coeff}}\label{lst:nram-avg-1}
					\State{GateResult = g.\Call{execute}{InputValue, IMem, MaxInt}}	
				\Else
					\State{(CoeffA, CoeffB) = \Call{GetGateCoefficient}{Conf, g}}
					\State{InputValueA = \Call{Avg}{RegsAndOutput, CoeffA}}\label{lst:nram-avg-2}
					\State{InputValueB = \Call{Avg}{RegsAndOutput, CoeffB}}\label{lst:nram-avg-3}
					\State{GateResult = g.\Call{execute}{GateValueA, GateValueB, IMem, MaxInt}}	
				\EndIf
				\State{RegsAndOutput = \Call{Concatenate}{Regs, GateValue}}
			\EndFor{}\label{lst:nram-exec-circuit-2}
			\newline
			\For{$i\in[1, \dots, |\textrm{Regs}|]$}\Comment{Update of the registers}\label{lst:nram-up-reg-1}
				\State{Coeff = \Call{GetGateCoefficient}{Conf, i}}
				\State{NewValue = \Call{Avg}{RegsAndOutput, Coeff}}\label{lst:nram-avg-4}
				\State{Regs[i] = NewValue}
			\EndFor{}\label{lst:nram-up-reg-2}
			\State{}
			\State{\Return{(Conf[|Conf| - 1], Distributions)}}
		\EndFunction
	\end{algorithmic}
	\caption{Run circuit function pseudocode.}\label{alg:nram-run-circuit}
\end{algorithm}


\begin{algorithm}
	\begin{algorithmic}[1]
		\Function{Avg}{RegsOut, Coefficient} 
			\State{\Return{RegsOut * Coefficient}}
		\EndFunction
	\end{algorithmic}
	\caption{Avg function pseudocode}\label{alg:nram-average}
\end{algorithm}

