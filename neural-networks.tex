\label{sl-nn}
In this chapter we will make a an overview about neural networks and some other concepts  for better explain the following parts of the thesis.

\section{Introduction}
The Neural Networks is a family of classification technique\footnote{Classification is the operation of learning a function \textbf{$f$} that map example records \textbf{$x \in D$}, where $D$ is the set of \textbf{$(x, y)$}, to the labels set \textbf{$y$} (the classes). This target function is called also Classification Model and is used in a descriptive or predictive way problem depending.}, that are inspired by the human brain: in particular by the connections inside this latter. The human brain consists principally of nerve cells called \textbf{neurons}, that are connected together via the \textbf{axons}\footnote{Inserirne una, se serve} used to transmit the electrical impulse by a neuron to another. This electrical impulse generated by a stimulated neuron is transferred to another one via the dendrites, a particular elements in the human brain used to connect two neuron: this point of contact is called synapse. \newline Analogously the internal structure of a Neural Network is composed by components, which are called \textbf{neurons}, connected together by directed links. There are many types of Neural Networks, but for the sake of simplicity and  for the scope of the thesis we will focus the attention to feedforward neural network model, explaining firstly the Perceptron model.
\subsection{	Perceptron}
The Perceptron model is the basic and simplest type of Neural Network, proposed firstly by Frank Rosenblatt in 1958. This model is composed only by two types of nodes called \textbf{input nodes} and \textbf{output node}, as we can see in the figure \ref{fig:perceptron-1}. As we can see in this latter the input nodes and the output node are connected by weighted links, similarly the human brain, that are used to simulate the synaptic connection strength.

\subsection{Multi Layer Perceptron (MLP)}
